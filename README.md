# ğŸ™ï¸ Multilanguage Voice Assistant â€” Whisper + ChatGPT + gTTS

> **DIO Bootcamp challenge:** Building a voice-powered conversational AI assistant that understands spoken questions in multiple languages and responds with synthesized speech â€” combining OpenAI Whisper, ChatGPT, and Google Text-to-Speech.

---

## Overview

This project was developed as part of a **DIO Bootcamp challenge** and demonstrates the integration of three powerful AI tools into a single, cohesive voice assistant pipeline:

1. **OpenAI Whisper** â€” transcribes and translates spoken audio input across multiple languages
2. **ChatGPT (OpenAI API)** â€” processes the transcribed text and generates accurate, contextual responses
3. **Google Text-to-Speech (gTTS)** â€” converts ChatGPT's text response back into spoken audio

The result is an end-to-end **voice-to-voice AI assistant** capable of understanding and responding to questions spoken in different languages â€” no typing required.

---

## How It Works

```
ğŸ¤ User speaks a question (any language)
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   OpenAI Whisper       â”‚  â† Speech-to-Text + Translation
â”‚   Audio transcription  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚  Transcribed text
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ChatGPT API          â”‚  â† Natural Language Understanding
â”‚   Response generation  â”‚     + Contextual answer
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚  Text response
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Google TTS (gTTS)    â”‚  â† Text-to-Speech synthesis
â”‚   Audio output         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
ğŸ”Š Assistant speaks the answer
```

---

## Tech Stack

| Component | Technology | Role |
|---|---|---|
| **Speech-to-Text** | OpenAI Whisper | Transcribes and translates spoken audio |
| **Language Model** | OpenAI ChatGPT API | Understands questions and generates responses |
| **Text-to-Speech** | Google gTTS | Converts text responses into spoken audio |
| **Language** | Python | Pipeline orchestration and API integration |

---

## Features

- ğŸ¤ **Voice input** â€” captures spoken questions from the microphone
- ğŸŒ **Multilanguage support** â€” Whisper understands and translates across multiple languages
- ğŸ¤– **AI-powered responses** â€” ChatGPT generates accurate, contextual answers
- ğŸ”Š **Voice output** â€” gTTS brings responses to life as synthesized speech
- âš¡ **End-to-end pipeline** â€” fully automated voice-to-voice interaction

---

## Key Concepts Demonstrated

**Speech-to-Text with Whisper**
OpenAI's Whisper model is one of the most robust transcription tools available, capable of handling accents, background noise, and multiple languages with high accuracy. In this project it serves as the entry point â€” converting the user's voice into processable text.

**Prompt Engineering with ChatGPT**
The transcribed text is sent to the ChatGPT API with a structured prompt that instructs the model to respond concisely and in the appropriate language â€” demonstrating practical prompt design for voice-first interactions.

**Text-to-Speech with gTTS**
Google's Text-to-Speech library converts ChatGPT's text response into an audio file that is played back to the user, closing the voice-to-voice loop without requiring any manual reading.

**API Integration**
The project connects three separate AI APIs (OpenAI Whisper, OpenAI ChatGPT, Google gTTS) in a single Python pipeline â€” a pattern directly applicable to production-grade AI assistant architectures.

---

## Installation

```bash
# Clone the repository
git clone https://github.com/YOUR_USERNAME/bootcamp-multilanguage-voice-assistant-whisper-chatgpt.git
cd bootcamp-multilanguage-voice-assistant-whisper-chatgpt

# Install dependencies
pip install -r requirements.txt
```

**Required packages:**
```
openai
openai-whisper
gtts
pygame
sounddevice
scipy
```

---

## Configuration

Create a `.env` file in the root directory with your OpenAI API key:

```env
OPENAI_API_KEY=your_api_key_here
```

> âš ï¸ Never commit your `.env` file. Make sure it is listed in `.gitignore`.

---

## How to Run

```bash
python main.py
```

Speak your question when prompted. The assistant will transcribe, process, and respond by voice.

---

## Repository Structure

```
bootcamp-multilanguage-voice-assistant-whisper-chatgpt/
â”œâ”€â”€ main.py                  # Main pipeline â€” record â†’ transcribe â†’ respond â†’ speak
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ .env.example             # Environment variable template
â”œâ”€â”€ .gitignore               # Excludes .env and audio temp files
â””â”€â”€ README.md
```

---

## What I Learned

- How to integrate **OpenAI Whisper** for multilanguage Speech-to-Text transcription
- How to use the **ChatGPT API** to generate contextual responses from voice input
- How to implement **gTTS** for Text-to-Speech audio synthesis in Python
- How to chain **multiple AI APIs** into a cohesive, real-time voice pipeline
- The architecture behind modern **voice assistant systems**

---

# ğŸ™ï¸ Assistente de Voz MultilÃ­ngue â€” Whisper + ChatGPT + gTTS

> **Desafio de Bootcamp DIO:** ConstruÃ§Ã£o de um assistente de IA conversacional por voz que entende perguntas faladas em mÃºltiplos idiomas e responde com voz sintetizada â€” combinando OpenAI Whisper, ChatGPT e Google Text-to-Speech.

---

## VisÃ£o Geral

Este projeto foi desenvolvido como um **desafio do Bootcamp da DIO** e demonstra a integraÃ§Ã£o de trÃªs poderosas ferramentas de IA em um Ãºnico pipeline de assistente de voz:

1. **OpenAI Whisper** â€” transcreve e traduz Ã¡udio de entrada falado em mÃºltiplos idiomas
2. **ChatGPT (OpenAI API)** â€” processa o texto transcrito e gera respostas precisas e contextuais
3. **Google Text-to-Speech (gTTS)** â€” converte a resposta textual do ChatGPT em Ã¡udio falado

O resultado Ã© um **assistente de IA voz-a-voz** capaz de entender e responder perguntas faladas em diferentes idiomas â€” sem necessidade de digitaÃ§Ã£o.

---

## Como Funciona

```
ğŸ¤ UsuÃ¡rio faz uma pergunta por voz (qualquer idioma)
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   OpenAI Whisper       â”‚  â† Speech-to-Text + TraduÃ§Ã£o
â”‚   TranscriÃ§Ã£o de Ã¡udio â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚  Texto transcrito
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ChatGPT API          â”‚  â† CompreensÃ£o de linguagem natural
â”‚   GeraÃ§Ã£o de resposta  â”‚     + Resposta contextual
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚  Resposta em texto
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Google TTS (gTTS)    â”‚  â† SÃ­ntese Text-to-Speech
â”‚   SaÃ­da de Ã¡udio       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
ğŸ”Š Assistente fala a resposta
```

---

## Stack

| Componente | Tecnologia | FunÃ§Ã£o |
|---|---|---|
| **Speech-to-Text** | OpenAI Whisper | Transcreve e traduz Ã¡udio falado |
| **Modelo de Linguagem** | OpenAI ChatGPT API | Entende perguntas e gera respostas |
| **Text-to-Speech** | Google gTTS | Converte respostas em Ã¡udio sintetizado |
| **Linguagem** | Python | OrquestraÃ§Ã£o do pipeline e integraÃ§Ã£o de APIs |

---

## Funcionalidades

- ğŸ¤ **Entrada por voz** â€” captura perguntas faladas pelo microfone
- ğŸŒ **Suporte multilÃ­ngue** â€” Whisper entende e traduz mÃºltiplos idiomas
- ğŸ¤– **Respostas com IA** â€” ChatGPT gera respostas precisas e contextuais
- ğŸ”Š **SaÃ­da por voz** â€” gTTS traz as respostas Ã  vida como fala sintetizada
- âš¡ **Pipeline completo** â€” interaÃ§Ã£o voz-a-voz totalmente automatizada

---

## Conceitos Demonstrados

**Speech-to-Text com Whisper**
O modelo Whisper da OpenAI Ã© uma das ferramentas de transcriÃ§Ã£o mais robustas disponÃ­veis, capaz de lidar com sotaques, ruÃ­do de fundo e mÃºltiplos idiomas com alta precisÃ£o. Neste projeto serve como ponto de entrada â€” convertendo a voz do usuÃ¡rio em texto processÃ¡vel.

**Engenharia de Prompt com ChatGPT**
O texto transcrito Ã© enviado Ã  API do ChatGPT com um prompt estruturado que instrui o modelo a responder de forma concisa e no idioma apropriado â€” demonstrando design prÃ¡tico de prompts para interaÃ§Ãµes voice-first.

**Text-to-Speech com gTTS**
A biblioteca Google Text-to-Speech converte a resposta textual do ChatGPT em um arquivo de Ã¡udio reproduzido ao usuÃ¡rio, fechando o ciclo voz-a-voz sem exigir leitura manual.

**IntegraÃ§Ã£o de APIs**
O projeto conecta trÃªs APIs de IA distintas (OpenAI Whisper, OpenAI ChatGPT, Google gTTS) em um Ãºnico pipeline Python â€” um padrÃ£o diretamente aplicÃ¡vel a arquiteturas de assistentes de IA em produÃ§Ã£o.

---

## InstalaÃ§Ã£o

```bash
# Clonar o repositÃ³rio
git clone https://github.com/YOUR_USERNAME/bootcamp-multilanguage-voice-assistant-whisper-chatgpt.git
cd bootcamp-multilanguage-voice-assistant-whisper-chatgpt

# Instalar dependÃªncias
pip install -r requirements.txt
```

**Pacotes necessÃ¡rios:**
```
openai
openai-whisper
gtts
pygame
sounddevice
scipy
```

---

## ConfiguraÃ§Ã£o

Crie um arquivo `.env` na raiz do projeto com sua chave da API OpenAI:

```env
OPENAI_API_KEY=sua_chave_aqui
```

> âš ï¸ Nunca faÃ§a commit do arquivo `.env`. Certifique-se de que estÃ¡ listado no `.gitignore`.

---

## Como Executar

```bash
python main.py
```

Fale sua pergunta quando solicitado. O assistente vai transcrever, processar e responder por voz.

---

## Estrutura do RepositÃ³rio

```
bootcamp-multilanguage-voice-assistant-whisper-chatgpt/
â”œâ”€â”€ main.py                  # Pipeline principal â€” gravar â†’ transcrever â†’ responder â†’ falar
â”œâ”€â”€ requirements.txt         # DependÃªncias Python
â”œâ”€â”€ .env.example             # Template de variÃ¡veis de ambiente
â”œâ”€â”€ .gitignore               # Exclui .env e arquivos de Ã¡udio temporÃ¡rios
â””â”€â”€ README.md
```

---

## O que Aprendi

- Como integrar o **OpenAI Whisper** para transcriÃ§Ã£o Speech-to-Text multilÃ­ngue
- Como usar a **API do ChatGPT** para gerar respostas contextuais a partir de entrada de voz
- Como implementar **gTTS** para sÃ­ntese de Ã¡udio Text-to-Speech em Python
- Como encadear **mÃºltiplas APIs de IA** em um pipeline de voz coeso e em tempo real
- A arquitetura por trÃ¡s de sistemas modernos de **assistentes de voz**
